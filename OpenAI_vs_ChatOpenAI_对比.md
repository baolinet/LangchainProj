# OpenAI vs ChatOpenAI è¯¦ç»†å¯¹æ¯”

## ğŸ¯ æ ¸å¿ƒåŒºåˆ«

åœ¨ `langchain_openai` åº“ä¸­ï¼Œ`OpenAI` å’Œ `ChatOpenAI` æ˜¯ä¸¤ä¸ªä¸åŒçš„ç±»ï¼Œå¯¹åº”ä¸åŒçš„APIç«¯ç‚¹å’Œä½¿ç”¨åœºæ™¯ï¼š

| ç‰¹æ€§ | OpenAI | ChatOpenAI |
|------|--------|------------|
| **APIç«¯ç‚¹** | `/completions` | `/chat/completions` |
| **è¾“å…¥æ ¼å¼** | å­—ç¬¦ä¸² | æ¶ˆæ¯åˆ—è¡¨ |
| **ä½¿ç”¨åœºæ™¯** | æ–‡æœ¬å®Œæˆ | å¯¹è¯èŠå¤© |
| **ç°ä»£æ”¯æŒ** | é€æ¸è¢«å¼ƒç”¨ | ä¸»æµæ¨è |

## ğŸ“ ä»£ç ç¤ºä¾‹å¯¹æ¯”

### 1. OpenAI (ä¼ ç»Ÿæ–‡æœ¬å®Œæˆ)

```python
from langchain_openai import OpenAI

# åˆå§‹åŒ–
llm = OpenAI(
    openai_api_key="your-api-key",
    openai_api_base="your-base-url",
    model="your-model",
    temperature=0.6
)

# ä½¿ç”¨ - ç›´æ¥ä¼ å…¥å­—ç¬¦ä¸²
response = llm.invoke("ä½ å¥½ï¼Œè¯·ä»‹ç»ä¸€ä¸‹è‡ªå·±")
print(response)  # ç›´æ¥è¾“å‡ºå­—ç¬¦ä¸²
```

### 2. ChatOpenAI (ç°ä»£èŠå¤©API)

```python
from langchain_openai import ChatOpenAI
from langchain_core.messages import HumanMessage

# åˆå§‹åŒ–
llm = ChatOpenAI(
    openai_api_key="your-api-key",
    openai_api_base="your-base-url",
    model="your-model",
    temperature=0.6
)

# ä½¿ç”¨ - éœ€è¦æ¶ˆæ¯æ ¼å¼
messages = [HumanMessage(content="ä½ å¥½ï¼Œè¯·ä»‹ç»ä¸€ä¸‹è‡ªå·±")]
response = llm.invoke(messages)
print(response.content)  # éœ€è¦è®¿é—® .content å±æ€§
```

## ğŸ” ä¸ºä»€ä¹ˆæ‚¨çš„ä»£ç æŠ¥é”™ï¼Ÿ

æ‚¨é‡åˆ°çš„é—®é¢˜æ˜¯å› ä¸ºï¼š

1. **APIç«¯ç‚¹ä¸åŒ¹é…**: æ‚¨çš„API `https://api-77aaidn1l8c5b7xa.aistudio-app.com/v1` å¯èƒ½åªæ”¯æŒèŠå¤©å®Œæˆç«¯ç‚¹ (`/chat/completions`)ï¼Œä¸æ”¯æŒä¼ ç»Ÿçš„æ–‡æœ¬å®Œæˆç«¯ç‚¹ (`/completions`)

2. **ç°ä»£APIè¶‹åŠ¿**: å¤§å¤šæ•°ç°ä»£AIæœåŠ¡æä¾›å•†éƒ½é‡‡ç”¨èŠå¤©æ ¼å¼çš„APIï¼Œå› ä¸ºå®ƒæ›´çµæ´»ï¼Œæ”¯æŒå¤šè½®å¯¹è¯å’Œè§’è‰²è®¾å®š

## âœ… æ¨èè§£å†³æ–¹æ¡ˆ

### æ–¹æ¡ˆ1: ä½¿ç”¨ ChatOpenAI (æ¨è)

```python
from langchain_openai import ChatOpenAI
from langchain_core.messages import HumanMessage, SystemMessage

llm = ChatOpenAI(
    openai_api_key="115925abb19ec543cdcbe8af4506ff463ea2b5e8",
    openai_api_base="https://api-77aaidn1l8c5b7xa.aistudio-app.com/v1",
    model="gemma3:27b",
    temperature=0.6
)

# ç®€å•å¯¹è¯
response = llm.invoke([HumanMessage(content="ä½ å¥½ï¼Œè¯·ä»‹ç»ä¸€ä¸‹è‡ªå·±")])
print(response.content)

# å¸¦ç³»ç»Ÿæç¤ºçš„å¯¹è¯
messages = [
    SystemMessage(content="ä½ æ˜¯ä¸€ä½å‹å¥½çš„AIåŠ©æ‰‹"),
    HumanMessage(content="ä½ å¥½ï¼Œè¯·ä»‹ç»ä¸€ä¸‹è‡ªå·±")
]
response = llm.invoke(messages)
print(response.content)
```

### æ–¹æ¡ˆ2: å¦‚æœå¿…é¡»ä½¿ç”¨ OpenAI æ ¼å¼

å¦‚æœæ‚¨çš„APIç¡®å®æ”¯æŒä¼ ç»Ÿçš„æ–‡æœ¬å®Œæˆï¼Œå¯èƒ½éœ€è¦ï¼š

```python
from langchain_openai import OpenAI

llm = OpenAI(
    openai_api_key="your-api-key",
    openai_api_base="your-base-url",
    model="your-model",
    temperature=0.6,
    # å¯èƒ½éœ€è¦é¢å¤–å‚æ•°
    max_tokens=150
)

response = llm.invoke("ä½ å¥½ï¼Œè¯·ä»‹ç»ä¸€ä¸‹è‡ªå·±")
print(response)
```

## ğŸš€ ChatOpenAI çš„ä¼˜åŠ¿

### 1. å¤šè½®å¯¹è¯æ”¯æŒ
```python
conversation = [
    SystemMessage(content="ä½ æ˜¯ä¸€ä½Pythonä¸“å®¶"),
    HumanMessage(content="ä»€ä¹ˆæ˜¯åˆ—è¡¨æ¨å¯¼å¼ï¼Ÿ"),
    AIMessage(content="åˆ—è¡¨æ¨å¯¼å¼æ˜¯Pythonä¸­åˆ›å»ºåˆ—è¡¨çš„ç®€æ´æ–¹å¼..."),
    HumanMessage(content="èƒ½ç»™ä¸ªä¾‹å­å—ï¼Ÿ")
]
response = llm.invoke(conversation)
```

### 2. è§’è‰²è®¾å®š
```python
messages = [
    SystemMessage(content="ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„è¥å…»å¸ˆï¼Œè¯·ç”¨ä¸“ä¸šæœ¯è¯­å›ç­”"),
    HumanMessage(content="å¦‚ä½•åˆ¶å®šå¥åº·é¥®é£Ÿè®¡åˆ’ï¼Ÿ")
]
```

### 3. æµå¼è¾“å‡º
```python
llm = ChatOpenAI(streaming=True, ...)
for chunk in llm.stream(messages):
    print(chunk.content, end="", flush=True)
```

## ğŸ› ï¸ å®é™…åº”ç”¨å»ºè®®

### 1. æ–°é¡¹ç›®
- **ä¼˜å…ˆä½¿ç”¨ ChatOpenAI**
- æ›´å¥½çš„å…¼å®¹æ€§å’Œæœªæ¥æ”¯æŒ
- æ›´ä¸°å¯Œçš„åŠŸèƒ½

### 2. è¿ç§»ç°æœ‰ä»£ç 
```python
# æ—§ä»£ç  (OpenAI)
response = llm.invoke("é—®é¢˜")

# æ–°ä»£ç  (ChatOpenAI)
response = llm.invoke([HumanMessage(content="é—®é¢˜")])
result = response.content
```

### 3. é”™è¯¯å¤„ç†
```python
try:
    # ä¼˜å…ˆå°è¯• ChatOpenAI
    chat_llm = ChatOpenAI(...)
    response = chat_llm.invoke([HumanMessage(content="æµ‹è¯•")])
    print(f"ä½¿ç”¨ ChatOpenAI: {response.content}")
except Exception as e:
    print(f"ChatOpenAI å¤±è´¥: {e}")
    
    try:
        # å¤‡é€‰æ–¹æ¡ˆï¼šOpenAI
        text_llm = OpenAI(...)
        response = text_llm.invoke("æµ‹è¯•")
        print(f"ä½¿ç”¨ OpenAI: {response}")
    except Exception as e2:
        print(f"OpenAI ä¹Ÿå¤±è´¥: {e2}")
```

## ğŸ“‹ æ€»ç»“

- **ChatOpenAI æ˜¯ç°ä»£æ¨èæ–¹æ¡ˆ**ï¼Œæ”¯æŒæ›´ä¸°å¯Œçš„åŠŸèƒ½
- **OpenAI æ˜¯ä¼ ç»Ÿæ–¹æ¡ˆ**ï¼Œå¯èƒ½åœ¨æŸäº›APIä¸Šä¸è¢«æ”¯æŒ
- **æ‚¨çš„APIæ›´å¯èƒ½æ”¯æŒ ChatOpenAI æ ¼å¼**
- **è¿ç§»å¾ˆç®€å•**ï¼šä¸»è¦æ˜¯è¾“å…¥è¾“å‡ºæ ¼å¼çš„è°ƒæ•´

é€‰æ‹© ChatOpenAIï¼Œæ‚¨å°†è·å¾—æ›´å¥½çš„å…¼å®¹æ€§å’Œæ›´å¤šåŠŸèƒ½ï¼
