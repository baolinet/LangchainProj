# LangChain OpenAI å®Œæ•´ç¤ºä¾‹
# pip install langchain-openai langchain-core

from langchain_openai import ChatOpenAI, OpenAI
from langchain_core.messages import HumanMessage, SystemMessage, AIMessage
from langchain_core.prompts import ChatPromptTemplate, PromptTemplate
from langchain_core.output_parsers import StrOutputParser
import time

# é…ç½®ä¿¡æ¯
API_KEY = "115925abb19ec543cdcbe8af4506ff463ea2b5e8"
BASE_URL = "https://api-k2k2a5teg1h0idd9.aistudio-app.com/v1"
MODEL_NAME = "qwq"

def example_1_basic_chat():
    """ç¤ºä¾‹1: åŸºç¡€èŠå¤©åŠŸèƒ½"""
    print("ğŸ”¥ ç¤ºä¾‹1: åŸºç¡€èŠå¤©åŠŸèƒ½")
    print("="*50)
    
    # åˆå§‹åŒ–ChatOpenAI
    llm = ChatOpenAI(
        openai_api_key=API_KEY,
        openai_api_base=BASE_URL,
        model=MODEL_NAME,
        temperature=0.7
    )
    
    # å•è½®å¯¹è¯
    message = HumanMessage(content="è¯·ç”¨ä¸€å¥è¯ä»‹ç»ä»€ä¹ˆæ˜¯äººå·¥æ™ºèƒ½")
    response = llm.invoke([message])
    print(f"ğŸ¤– AIå›å¤: {response.content}")
    print()

def example_2_system_prompt():
    """ç¤ºä¾‹2: ä½¿ç”¨ç³»ç»Ÿæç¤º"""
    print("ğŸ”¥ ç¤ºä¾‹2: ä½¿ç”¨ç³»ç»Ÿæç¤º")
    print("="*50)
    
    llm = ChatOpenAI(
        openai_api_key=API_KEY,
        openai_api_base=BASE_URL,
        model=MODEL_NAME,
        temperature=0.5
    )
    
    # å¤šè½®å¯¹è¯ï¼ŒåŒ…å«ç³»ç»Ÿæç¤º
    messages = [
        SystemMessage(content="ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„Pythonç¼–ç¨‹å¯¼å¸ˆï¼Œè¯·ç”¨ç®€æ´æ˜äº†çš„æ–¹å¼å›ç­”é—®é¢˜ã€‚"),
        HumanMessage(content="å¦‚ä½•åœ¨Pythonä¸­åˆ›å»ºä¸€ä¸ªåˆ—è¡¨ï¼Ÿ")
    ]
    
    response = llm.invoke(messages)
    print(f"ğŸ Pythonå¯¼å¸ˆ: {response.content}")
    print()

def example_3_streaming():
    """ç¤ºä¾‹3: æµå¼è¾“å‡º"""
    print("ğŸ”¥ ç¤ºä¾‹3: æµå¼è¾“å‡º")
    print("="*50)
    
    llm = ChatOpenAI(
        openai_api_key=API_KEY,
        openai_api_base=BASE_URL,
        model=MODEL_NAME,
        temperature=0.6,
        streaming=True
    )
    
    message = HumanMessage(content="è¯·è¯¦ç»†è§£é‡Šä»€ä¹ˆæ˜¯æœºå™¨å­¦ä¹ ï¼ŒåŒ…æ‹¬å…¶ä¸»è¦ç±»å‹")
    
    print("ğŸ¤– AIæ­£åœ¨å›å¤...")
    print("-" * 30)
    
    try:
        for chunk in llm.stream([message]):
            print(chunk.content, end="", flush=True)
        print("\n" + "-" * 30)
        print("âœ… æµå¼è¾“å‡ºå®Œæˆ")
    except Exception as e:
        print(f"âŒ æµå¼è¾“å‡ºå¤±è´¥: {e}")
    print()

def example_4_prompt_template():
    """ç¤ºä¾‹4: ä½¿ç”¨æç¤ºæ¨¡æ¿"""
    print("ğŸ”¥ ç¤ºä¾‹4: ä½¿ç”¨æç¤ºæ¨¡æ¿")
    print("="*50)
    
    llm = ChatOpenAI(
        openai_api_key=API_KEY,
        openai_api_base=BASE_URL,
        model=MODEL_NAME,
        temperature=0.7
    )
    
    # åˆ›å»ºèŠå¤©æç¤ºæ¨¡æ¿
    prompt = ChatPromptTemplate.from_messages([
        ("system", "ä½ æ˜¯ä¸€ä½{profession}ï¼Œè¯·ç”¨ä¸“ä¸šçš„è§’åº¦å›ç­”é—®é¢˜ã€‚"),
        ("human", "{question}")
    ])
    
    # åˆ›å»ºé“¾
    chain = prompt | llm | StrOutputParser()
    
    # è°ƒç”¨é“¾
    result = chain.invoke({
        "profession": "è¥å…»å¸ˆ",
        "question": "å¦‚ä½•åˆ¶å®šå¥åº·çš„é¥®é£Ÿè®¡åˆ’ï¼Ÿ"
    })
    
    print(f"ğŸ¥— è¥å…»å¸ˆå»ºè®®: {result}")
    print()

def example_5_conversation():
    """ç¤ºä¾‹5: å¤šè½®å¯¹è¯"""
    print("ğŸ”¥ ç¤ºä¾‹5: å¤šè½®å¯¹è¯")
    print("="*50)
    
    llm = ChatOpenAI(
        openai_api_key=API_KEY,
        openai_api_base=BASE_URL,
        model=MODEL_NAME,
        temperature=0.6
    )
    
    # æ¨¡æ‹Ÿå¤šè½®å¯¹è¯
    conversation = [
        SystemMessage(content="ä½ æ˜¯ä¸€ä½å‹å¥½çš„AIåŠ©æ‰‹ã€‚"),
        HumanMessage(content="ä½ å¥½ï¼"),
    ]
    
    # ç¬¬ä¸€è½®
    response1 = llm.invoke(conversation)
    conversation.append(response1)
    print(f"ğŸ‘¤ ç”¨æˆ·: ä½ å¥½ï¼")
    print(f"ğŸ¤– AI: {response1.content}")
    
    # ç¬¬äºŒè½®
    conversation.append(HumanMessage(content="ä½ èƒ½å¸®æˆ‘è§£é‡Šä¸€ä¸‹ä»€ä¹ˆæ˜¯æ·±åº¦å­¦ä¹ å—ï¼Ÿ"))
    response2 = llm.invoke(conversation)
    print(f"ğŸ‘¤ ç”¨æˆ·: ä½ èƒ½å¸®æˆ‘è§£é‡Šä¸€ä¸‹ä»€ä¹ˆæ˜¯æ·±åº¦å­¦ä¹ å—ï¼Ÿ")
    print(f"ğŸ¤– AI: {response2.content}")
    print()

def example_6_legacy_openai():
    """ç¤ºä¾‹6: ä½¿ç”¨ä¼ ç»ŸOpenAIæ¥å£ï¼ˆæ–‡æœ¬å®Œæˆï¼‰"""
    print("ğŸ”¥ ç¤ºä¾‹6: ä¼ ç»ŸOpenAIæ¥å£ï¼ˆæ–‡æœ¬å®Œæˆï¼‰")
    print("="*50)
    
    # æ³¨æ„ï¼šè¿™é‡Œä½¿ç”¨OpenAIè€Œä¸æ˜¯ChatOpenAI
    llm = OpenAI(
        openai_api_key=API_KEY,
        openai_api_base=BASE_URL,
        model=MODEL_NAME,
        temperature=0.7,
        max_tokens=100
    )
    
    prompt = "è¯·ç®€è¦ä»‹ç»Pythonç¼–ç¨‹è¯­è¨€çš„ç‰¹ç‚¹ï¼š"
    
    try:
        response = llm.invoke(prompt)
        print(f"ğŸ“ æ–‡æœ¬å®Œæˆ: {response}")
    except Exception as e:
        print(f"âŒ æ–‡æœ¬å®Œæˆå¤±è´¥: {e}")
        print("ğŸ’¡ æç¤º: æŸäº›APIå¯èƒ½ä¸æ”¯æŒä¼ ç»Ÿçš„æ–‡æœ¬å®Œæˆæ¥å£")
    print()

def example_7_batch_processing():
    """ç¤ºä¾‹7: æ‰¹é‡å¤„ç†"""
    print("ğŸ”¥ ç¤ºä¾‹7: æ‰¹é‡å¤„ç†")
    print("="*50)
    
    llm = ChatOpenAI(
        openai_api_key=API_KEY,
        openai_api_base=BASE_URL,
        model=MODEL_NAME,
        temperature=0.5
    )
    
    # æ‰¹é‡é—®é¢˜
    questions = [
        "ä»€ä¹ˆæ˜¯äººå·¥æ™ºèƒ½ï¼Ÿ",
        "ä»€ä¹ˆæ˜¯æœºå™¨å­¦ä¹ ï¼Ÿ",
        "ä»€ä¹ˆæ˜¯æ·±åº¦å­¦ä¹ ï¼Ÿ"
    ]
    
    print("ğŸ”„ æ‰¹é‡å¤„ç†é—®é¢˜...")
    for i, question in enumerate(questions, 1):
        message = HumanMessage(content=f"è¯·ç”¨ä¸€å¥è¯å›ç­”ï¼š{question}")
        response = llm.invoke([message])
        print(f"{i}. é—®é¢˜: {question}")
        print(f"   å›ç­”: {response.content}")
        time.sleep(1)  # é¿å…è¯·æ±‚è¿‡å¿«
    print()

def main():
    """ä¸»å‡½æ•° - è¿è¡Œæ‰€æœ‰ç¤ºä¾‹"""
    print("ğŸš€ LangChain OpenAI å®Œæ•´ç¤ºä¾‹é›†")
    print("ğŸŒŸ å±•ç¤ºå„ç§ä½¿ç”¨æ–¹å¼å’Œæœ€ä½³å®è·µ")
    print("="*60)
    print()
    
    examples = [
        example_1_basic_chat,
        example_2_system_prompt,
        example_3_streaming,
        example_4_prompt_template,
        example_5_conversation,
        example_6_legacy_openai,
        example_7_batch_processing
    ]
    
    for i, example_func in enumerate(examples, 1):
        try:
            example_func()
        except Exception as e:
            print(f"âŒ ç¤ºä¾‹{i}æ‰§è¡Œå¤±è´¥: {e}")
            print()
        
        if i < len(examples):
            print("â³ ç­‰å¾…2ç§’åç»§ç»­ä¸‹ä¸€ä¸ªç¤ºä¾‹...")
            time.sleep(2)
            print()
    
    print("ğŸ‰ æ‰€æœ‰ç¤ºä¾‹æ‰§è¡Œå®Œæˆï¼")
    print("="*60)

if __name__ == "__main__":
    main()
