# ChatOpenAI æœ€ä½³å®è·µç¤ºä¾‹
from langchain_openai import ChatOpenAI
from langchain_core.messages import HumanMessage, SystemMessage

def create_llm():
    """åˆ›å»ºChatOpenAIå®ä¾‹ - æ¨èæ–¹å¼"""
    return ChatOpenAI(
        openai_api_key="115925abb19ec543cdcbe8af4506ff463ea2b5e8",
        openai_api_base="https://api-77aaidn1l8c5b7xa.aistudio-app.com/v1",
        model="gemma3:27b",
        temperature=0.6
    )

def simple_chat():
    """ç®€å•èŠå¤©ç¤ºä¾‹ - æ­£ç¡®çš„æ–¹å¼"""
    print("ğŸ’¬ ç®€å•èŠå¤©ç¤ºä¾‹")
    print("-" * 30)
    
    llm = create_llm()
    
    # âœ… æ­£ç¡®ï¼šä½¿ç”¨æ¶ˆæ¯æ ¼å¼
    message = HumanMessage(content="ä½ å¥½ï¼Œè¯·ç”¨ä¸€å¥è¯ä»‹ç»è‡ªå·±")
    response = llm.invoke([message])
    print(f"ğŸ¤– AI: {response.content}")
    
    # âŒ é”™è¯¯ç¤ºä¾‹ï¼ˆä¼šæŠ¥é”™ï¼‰ï¼š
    # response = llm.invoke("ä½ å¥½ï¼Œè¯·ç”¨ä¸€å¥è¯ä»‹ç»è‡ªå·±")  # è¿™æ ·ä¼šæŠ¥é”™

def system_prompt_chat():
    """å¸¦ç³»ç»Ÿæç¤ºçš„èŠå¤© - ChatOpenAIçš„ä¼˜åŠ¿"""
    print("\nğŸ­ ç³»ç»Ÿæç¤ºç¤ºä¾‹")
    print("-" * 30)
    
    llm = create_llm()
    
    # âœ… ä½¿ç”¨ç³»ç»Ÿæç¤ºè®¾å®šè§’è‰²
    messages = [
        SystemMessage(content="ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„Pythonç¼–ç¨‹åŠ©æ‰‹ï¼Œå›ç­”è¦ç®€æ´æ˜äº†"),
        HumanMessage(content="ä»€ä¹ˆæ˜¯è£…é¥°å™¨ï¼Ÿ")
    ]
    response = llm.invoke(messages)
    print(f"ğŸ PythonåŠ©æ‰‹: {response.content}")

def streaming_example():
    """æµå¼è¾“å‡ºç¤ºä¾‹"""
    print("\nğŸŒŠ æµå¼è¾“å‡ºç¤ºä¾‹")
    print("-" * 30)
    
    # å¯ç”¨æµå¼è¾“å‡º
    llm = ChatOpenAI(
        openai_api_key="115925abb19ec543cdcbe8af4506ff463ea2b5e8",
        openai_api_base="https://api-77aaidn1l8c5b7xa.aistudio-app.com/v1",
        model="gemma3:27b",
        temperature=0.6,
        streaming=True
    )
    
    message = HumanMessage(content="è¯·ç®€è¦è§£é‡Šä»€ä¹ˆæ˜¯æœºå™¨å­¦ä¹ ")
    
    print("ğŸ¤– AIæ­£åœ¨å›å¤...")
    try:
        for chunk in llm.stream([message]):
            print(chunk.content, end="", flush=True)
        print("\nâœ… æµå¼è¾“å‡ºå®Œæˆ")
    except Exception as e:
        print(f"\nâŒ æµå¼è¾“å‡ºå¤±è´¥: {e}")

def error_handling_example():
    """é”™è¯¯å¤„ç†ç¤ºä¾‹"""
    print("\nğŸ›¡ï¸ é”™è¯¯å¤„ç†ç¤ºä¾‹")
    print("-" * 30)
    
    # æ¼”ç¤ºå¦‚ä½•ä¼˜é›…åœ°å¤„ç†é”™è¯¯
    try:
        llm = create_llm()
        message = HumanMessage(content="æµ‹è¯•è¿æ¥")
        response = llm.invoke([message])
        print(f"âœ… è¿æ¥æˆåŠŸ: {response.content[:50]}...")
    except Exception as e:
        print(f"âŒ è¿æ¥å¤±è´¥: {e}")
        print("ğŸ’¡ å»ºè®®æ£€æŸ¥:")
        print("   - APIå¯†é’¥æ˜¯å¦æ­£ç¡®")
        print("   - ç½‘ç»œè¿æ¥æ˜¯å¦æ­£å¸¸")
        print("   - APIç«¯ç‚¹æ˜¯å¦æ”¯æŒChatOpenAIæ ¼å¼")

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ ChatOpenAI æœ€ä½³å®è·µç¤ºä¾‹")
    print("="*50)
    print("ğŸ“š å­¦ä¹ è¦ç‚¹:")
    print("   â€¢ ä½¿ç”¨ ChatOpenAI è€Œä¸æ˜¯ OpenAI")
    print("   â€¢ è¾“å…¥å¿…é¡»æ˜¯æ¶ˆæ¯åˆ—è¡¨æ ¼å¼")
    print("   â€¢ è¾“å‡ºéœ€è¦è®¿é—® .content å±æ€§")
    print("   â€¢ æ”¯æŒç³»ç»Ÿæç¤ºå’Œå¤šè½®å¯¹è¯")
    print("="*50)
    
    examples = [
        simple_chat,
        system_prompt_chat,
        streaming_example,
        error_handling_example
    ]
    
    for example in examples:
        try:
            example()
        except Exception as e:
            print(f"âŒ ç¤ºä¾‹æ‰§è¡Œå¤±è´¥: {e}")
    
    print(f"\nğŸ‰ ç¤ºä¾‹æ¼”ç¤ºå®Œæˆï¼")
    print("ğŸ’¡ è®°ä½ï¼šChatOpenAI æ˜¯ç°ä»£æ¨èæ–¹æ¡ˆï¼Œå…¼å®¹æ€§æ›´å¥½ï¼")

if __name__ == "__main__":
    main()
